<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Ziwei Wang</title>
  
  <meta name="author" content="Ziwei Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ziwei Wang</name>
              </p>
              <p>Ziwei Wang is a PhD candidate at the <a href="http://ivg.au.tsinghua.edu.cn/">Intelligent Vision Group (IVG)</a>, Department of Automation, Tsinghua University, advised by Prof. <a href="http://www.au.tsinghua.edu.cn/info/1078/1627.htm">Jiwen Lu</a>.
                 He received the BS degree from the Department of Physics, Tsinghua University, China, in 2018.
                 His research interests include tiny machine learning, robotic vision and scene understanding. He has published over 20 scientific papers in the IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Robotics and Automation Letters, CVPR, ICCV, ECCV, IROS and ICRA. 
                 He serves as a regular reviewer member for the IEEE Transactions on Image Processing, IEEE Transactions on Circuits and Systems for Video Technology, Pattern Recognition Letters, CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, ICRA, WACV, ACCV, ICPR, ICME and ICIP.
              </p>
              <p style="text-align:center">
                <a href="wang-zw18@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=cMTW09EAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                 <a href="https://github.com/ZiweiWangTHU">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/icon.jpg"><img style="width:50%;max-width:50%" alt="profile photo" src="images/icon.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <li style="margin: 5px;" >
                <b>2023-03:</b> One paper on AutoML is accepted to <a href="https://www.springer.com/journal/11263">IJCV</a>.
                <li style="margin: 5px;" >
                <b>2023-02:</b> One paper on binary sparse convolutional networks is accepted to <a href="https://cvpr.thecvf.com">CVPR 2023</a>.
                <li style="margin: 5px;" >
                <b>2023-02:</b> One paper on binary neural networks is accepted to <a href="https://www.ejournal.org.cn/CN/0372-2112/home.shtml">Acta Electonica Sinica（电子学报）</a>.
                <li style="margin: 5px;" >
                <b>2023-01:</b> One paper on object shape estimation is accepted to <a href="https://www.icra2023.org">ICRA 2023</a>.
              </p>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Preprint</heading>
            <p>
                <li style="margin: 5px;" >
                Changyuan Wang, <strong>Ziwei Wang</strong>, Xiuwei Xu, Yansong Tang, Jie Zhou, Jiwen Lu. Towards Accurate Data-free Quantization for Diffusion Models. <a href="data/ADP-DM.pdf">[PDF]</a>
                Xiuwei Xu, Zhihao Sun, <strong>Ziwei Wang</strong>, Hongming Liu, Jie Zhou, Jiwen Lu. DSPDet3D: Dynamic Spatial Pruning for 3D Small Object Detection. <a href="data/DSPDet3D.pdf">[PDF]</a><a href="https://xuxw98.github.io/DSPDet3D/">[Website]</a>
            </p>
            </td>
          </tr>
        </tbody></table>
       

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/SeerNet.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Accurate Performance Predictors for Ultrafast Automated Model Compression</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Han Xiao, Shengyu Liu, Jie Zhou
              <br>
              <em>International Journal of Computer Vision (<strong>IJCV</strong>, IF: 13.37)</em>, 2023.
              <br>
              <a href="data/SeerNet.pdf">[PDF]</a>
              <a href="https://github.com/ZiweiWangTHU/SeerNet">[Code]</a>
              <br>
              <p> We propose an ultrafast auto- mated model compression framework for flexible network deployment, where we can obtain the optimal compression policy within several seconds.</p>
            </td>
          </tr>
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/BSC.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Binarizing Sparse Convolutional Networks for Efficient Point Cloud Analysis</papertitle>
              <br>
              Xiuwei Xu, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023.
              <br>
              <a href="data/BSC.pdf">[PDF]</a>
              <br>
              <p> we propose binary sparse convolutional networks for efficient point cloud analysis, where we search the optimal subset of convolution operation that activates the sparse convolution at various locations for quantization error alleviation.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ICRA23.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Category-level Shape Estimation for Densely Cluttered Objects</papertitle>
              <br>
              Zhenyu Wu, <strong>Ziwei Wang</strong>, Jiwen Lu, Haibin Yan
              <br>
              <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2023.
              <br>
              <a href="data/ICRA23.pdf">[PDF]</a>
              <a href="https://github.com/Gary3410/Shape-Estimation">[Code]</a>
              <br>
              <p> We propose a category-level shape estimation method for densely cluttered objects, which addresses the challenges of large object segmentation errors and inaccurate shape recovery on unseen instances.</p>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Quantformer.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Quantformer: Learning Extremely Low-precision Vision Transformers</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Changyuan Wang, Xiuwei Xu, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>, IF: 24.31)</em>, 2022.
              <br>
              <a href="data/Quantformer.pdf">[PDF]</a>
              <a href="data/Quantformer-supp.pdf">[Supp]</a>
              <a href="https://github.com/ZiweiWangTHU/Quantformer">[Code]</a>
              <br>
              <p> We propose the extremely low-precision vision transformers in 2-4 bits, where the self-attention rank consistency and group-wise quantization are presented for quantization error minimization. </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PackingPlanning.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Planning Irregular Object Packing via Hierarchical Reinforcement Learning</papertitle>
              <br>
              Sichao Huang, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE Robotics and Automation Letters (<strong>RAL</strong>)</em>, 2022
              <br>
              <a href="data/PackingPlanning.pdf">[PDF]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing/blob/main/video_demo/demo_robot.mp4">[Robot Demo]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing/blob/main/video_demo/demo_simulation.mp4">[Simulation Demo]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing">[Code]</a>
              <br>
              <p></p>
              <p>we develop a packing planning method for general objects including the packing sequence, locations and orientations to maximize the space utilization ratio.</p>
            </td>
          </tr>
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Fig_Shap-CAM.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Shap-CAM: Visual Explanations for Convolutional Neural Networks based on Shapley Value</papertitle>
              <br>
              Quan Zheng, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>17th European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2022
              <br>
              <a href="data/Shap-CAM.pdf">[PDF]</a>
              <br>
              <p></p>
              <p>we develop a post-hoc visual explanation method based on the Shapley value in class activation mapping.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Fig_Smart Explorer.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Smart Explorer: Recognizing Objects in Dense Clutter via Interactive Exploration</papertitle>
              <br>
              Zhenyu Wu*, <strong>Ziwei Wang*</strong>, Zibu Wei, Yi Wei, Haibin Yan
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2022.
              <br>
              <a href="data/Smart Explorer.pdf">[PDF]</a>
              <a href="data/IROS22_0255_VI_fi.mp4">[Demo]</a>
              <a href="https://github.com/Gary3410/Smart-Explorer">[Code]</a>
              <br>
              <p></p>
              <p>We propose an interactive exploration framework called Smart Explorer for recognizing all objects in dense clutters.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Fig_GE-Grasp.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GE-Grasp: Efficeint Target Oriented Grasping in Dense Clutter</papertitle>
              <br>
              Zhan Liu, <strong>Ziwei Wang</strong>, Sichao Huang, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2022.
              <br>
              <a href="data/GE-Grasp.pdf">[PDF]</a>
              <a href="data/IROS22_0216_VI_fi.mp4">[Demo]</a>
              <a href="https://github.com/CaptainWuDaoKou/GE-Grasp">[Code]</a>
              <br>
              <p></p>
              <p>we present a generic framework for robotic motion planning in dense clutter with diverse action primitives and generator-evaluator architectures.</p>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/D-GraphBit.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Deep Binary Descriptors via Bitwise Interaction Mining</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Han Xiao, Yueqi Duan, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>, IF: 24.31)</em>, 2022.
              <br>
              <a href="data/D-GraphBit.pdf">[PDF]</a> </a><a href="https://github.com/ZiweiWangTHU/GraphBit">[Code]</a>
              <br>
              <p> We propose the unsupervised binary descriptor learning method via dynamic bitwise interaction mining (D-GraphBit), where a graph convolutional network called GraphMiner reasons the optimal bitwise interaction for each input sample. </p>
            </td>
          </tr>
          
          
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Shapley-NAS.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search</papertitle>
              <br>
              Han Xiao, <strong>Ziwei Wang</strong>, Zheng Zhu, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022.
              <br>
              <a href="data/04143.pdf">[PDF]</a>
              <a href="data/04143-supp.pdf">[Supplement]</a>
              <a href="https://github.com/Euphoria16/Shapley-NAS">[Code]</a>
              <br>
              <p></p>
              <p>We propose a Shapley value based method to evaluate operation contribution (Shapley-NAS) for neural architecture search.</p>
            </td>
          </tr>
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GMPQ.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Generalizable Mixed-Precision Quantization via Attribution Rank Preservation</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Han Xiao, Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021.
              <br>
              <a href="data/02669.pdf">[PDF]</a>
              <a href="data/02669-supp.pdf">[Supplement]</a>
              <a href="https://github.com/ZiweiWangTHU/GMPQ">[Code]</a>
              <br>
              <p></p>
              <p>We propose a generalizable mixed-precision quantization (GMPQ) method for efficient inference.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ISL.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Instance Similarity Learning for Unsupervised Feature Representation</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Yunsong Wang, Ziyi Wu, Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021.
              <br>
              <a href="data/08812.pdf">[PDF]</a>
              <a href="data/08812-supp.pdf">[Supplement]</a>
              <a href="https://github.com/ZiweiWangTHU/ISL">[Code]</a>
              <br>
              <p></p>
              <p>We propose an instance similarity learning (ISL) method for unsupervised feature representation.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/AutoBiDet_Pipeline.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Efficient Binarized Object Detectors with Information Compression</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Ziyi Wu, Jie Zhou
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>, IF: 24.31)</em>, 2022.
              <br>
              <a href="data/AutoBiDet.pdf">[PDF]</a>
              <a href="data/AutoBiDet-supp.pdf">[Supplement]</a>
              <a href="https://github.com/ZiweiWangTHU/BiDet">[Code]</a>
              <br>
              <p></p>
              <p>We propose apresent binary neural networks with automatic information compression (AutoBiDet) to automatically adjust the IB trade-off according to the input complexity.</p>
            </td>
          </tr>
          
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/HCI-BCNN.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Channel-Wise Interactions for Binary Convolutional Neural Networks</papertitle>
              <br>
              <strong>Ziwei Wang</strong>,  Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>, IF: 24.31)</em>, 2021.
              <br>
              <a href="data/channel-wise interactions.pdf">[PDF]</a> <a href="data/channel-wise interactions-supp.pdf">[Supplement]</a><a href="https://github.com/ZiweiWangTHU/CI-BCNN">[Code]</a>
              <br>
              <p> We present a hierarchical channel-wise interaction based binary convolutional neural networks (HCI-BCNN) method to minimize the quantiztaion error for activations via hierarchical reinforcement learning. </p>
            </td>
          </tr>
          
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/DH-APS.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Deep Hashing with Active Pairwise Supervision</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Quan Zheng, Jiwen Lu, Jie Zhou
              <br>
              <em>16th European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020
              <br>
              <a href="data/3281.pdf">[PDF]</a>
              <a href="data/3281-supp.pdf">[Supplement]</a>
              <a href="data/3281-slides.pdf">[Slides]</a>
              <a href="data/3281-short video.pdf">[Video]</a>
              <br>
              <p></p>
              <p>We propose a Deep Hashing method with Active Pairwise Supervision (DH-APS) to learn effective binary codes for image search with limited annotation budget.</p>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/BiDet.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>BiDet: An Efficient Binarized Object Detector</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Ziyi Wu, Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
              <br>
              <a href="data/05105.pdf">[PDF]</a> <a href="https://github.com/ZiweiWangTHU/BiDet">[Code]</a>
              <br>
              <p></p>
              <p>We propose an efficient binarized object detector that fully utilizes the representational capacity of the binary neural networks by redundancy removal</strong>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/CI-BCNN.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Channel-wise Interactions for Binary Convolutional Neural Networks</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Chenxin Tao, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2019
              <br>
              <a href="data/1279.pdf">[PDF]</a> <a href="https://github.com/ZiweiWangTHU/CI-BCNN">[Code]</a> 
              <br>
              <p> We propose a channel-wise interaction based binary convolutional neural network learning method (CI-BCNN) for efficient inference with minimal information loss. </p>
            </td>
          </tr>

      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/DCBD-MQ.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Deep Binary Descriptor with Multi-Quantization</papertitle>
              <br>
              Yueqi Duan, Jiwen Lu, <strong>Ziwei Wang</strong>, Jianjiang Feng, Jie Zhou
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>, IF: 24.31)</em>, 2019.
              <br>
              <a href="data/multi-quantization.pdf">[PDF]</a>
              <br>
              <p> We present a deep multi-quantization network to learn a data-dependent binarization for unsupervised features. </p>
            </td>
          </tr>
   

         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/GraphBit.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GraphBit: Bitwise Interaction Mining via Deep Reinforcement Learning</papertitle>
              <br>
              Yueqi Duan, <strong>Ziwei Wang</strong>, Jiwen Lu, Xudong Lin, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2018
              <br>          
              <br>
              <a href="data/348.pdf">[PDF]</a> <a href="https://github.com/ZiweiWangTHU/GraphBit">[Code]</a>
              <br>
              <p> We propose a GraphBit method to learn deep binary descriptors with enhanced reliability in a directed acyclic graph unsupervisedly. </p>
            </td>
          </tr>

           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/DBD-MQ.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Deep Binary Descriptor with Multi-Quantization</papertitle>
              <br>
              Yueqi Duan, Jiwen Lu, <strong>Ziwei Wang</strong>, Jianjiang Feng, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2017
              <br>          
              <br>
              <a href="data/CVPR17.pdf">[PDF]</a>
              <br>
              <p> We present an unsupervised feature learning method called deep binary descriptor with multiquantization (DBD-MQ) for visual matching. </p>
            </td>
          </tr>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> 2022 National Scholarship</li>
                <li style="margin: 5px;"> 2020 National Scholarship</li>
                <li style="margin: 5px;"> 2018 Chi-Sun Yeh Scholarship </li>
                <li style="margin: 5px;"> 2016 Qualcomm Scholarship</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> CVPR 2020/2021/2022/2023, ICCV 2021, ECCV 2022, NeurIPS 2020/2021/2022, ICML2021/2022/2023, ICLR 2021/2022/2023, IJCAI 2022, ICRA 2023
              </li>
              <li style="margin: 5px;"> 
                <b>Journal Reviewer:</b>  T-IP, T-CSVT, T-BIOM, Pattern Recognition Letters, JVIC
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
